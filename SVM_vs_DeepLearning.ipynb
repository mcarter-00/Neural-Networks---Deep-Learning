{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and contrast the performance of an SVM versus deep learning model. Build a binary classifier using an support vector machine (SVM) and deep learning model to predict whether or not a customer is likely to subscribe to a banking service after being targeted by telemarketing advertisements. Compare the predictive accuracy of either model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Education</th>\n",
       "      <th>Default_Credit</th>\n",
       "      <th>Housing_Loan</th>\n",
       "      <th>Personal_Loan</th>\n",
       "      <th>Subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>other</td>\n",
       "      <td>married</td>\n",
       "      <td>Primary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>Secondary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>Primary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>Secondary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>Professional_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age       Job Marital_Status               Education Default_Credit  \\\n",
       "0   56     other        married       Primary_Education             no   \n",
       "1   37  services        married     Secondary_Education             no   \n",
       "2   40     admin        married       Primary_Education             no   \n",
       "3   56  services        married     Secondary_Education             no   \n",
       "4   59     admin        married  Professional_Education             no   \n",
       "\n",
       "  Housing_Loan Personal_Loan Subscribed  \n",
       "0           no            no         no  \n",
       "1          yes            no         no  \n",
       "2           no            no         no  \n",
       "3           no           yes         no  \n",
       "4           no            no         no  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import our input dataset\n",
    "tele_df = pd.read_csv('bank_telemarketing.csv')\n",
    "tele_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that none of our categorical variables require bucketing. Get the column names of categorical variables and check their number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job               9\n",
       "Marital_Status    3\n",
       "Education         4\n",
       "Default_Credit    2\n",
       "Housing_Loan      2\n",
       "Personal_Loan     2\n",
       "Subscribed        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "tele_cat = tele_df.dtypes[tele_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "tele_df[tele_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the number of unique values for each categorical variable, there were no categories that require bucketing prior to encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_admin</th>\n",
       "      <th>Job_blue-collar</th>\n",
       "      <th>Job_entrepreneur</th>\n",
       "      <th>Job_management</th>\n",
       "      <th>Job_other</th>\n",
       "      <th>Job_retired</th>\n",
       "      <th>Job_self-employed</th>\n",
       "      <th>Job_services</th>\n",
       "      <th>Job_technician</th>\n",
       "      <th>Marital_Status_divorced</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_Secondary_Education</th>\n",
       "      <th>Education_Tertiary_Education</th>\n",
       "      <th>Default_Credit_no</th>\n",
       "      <th>Default_Credit_yes</th>\n",
       "      <th>Housing_Loan_no</th>\n",
       "      <th>Housing_Loan_yes</th>\n",
       "      <th>Personal_Loan_no</th>\n",
       "      <th>Personal_Loan_yes</th>\n",
       "      <th>Subscribed_no</th>\n",
       "      <th>Subscribed_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Job_admin  Job_blue-collar  Job_entrepreneur  Job_management  Job_other  \\\n",
       "0        0.0              0.0               0.0             0.0        1.0   \n",
       "1        0.0              0.0               0.0             0.0        0.0   \n",
       "2        1.0              0.0               0.0             0.0        0.0   \n",
       "3        0.0              0.0               0.0             0.0        0.0   \n",
       "4        1.0              0.0               0.0             0.0        0.0   \n",
       "\n",
       "   Job_retired  Job_self-employed  Job_services  Job_technician  \\\n",
       "0          0.0                0.0           0.0             0.0   \n",
       "1          0.0                0.0           1.0             0.0   \n",
       "2          0.0                0.0           0.0             0.0   \n",
       "3          0.0                0.0           1.0             0.0   \n",
       "4          0.0                0.0           0.0             0.0   \n",
       "\n",
       "   Marital_Status_divorced  ...  Education_Secondary_Education  \\\n",
       "0                      0.0  ...                            0.0   \n",
       "1                      0.0  ...                            1.0   \n",
       "2                      0.0  ...                            0.0   \n",
       "3                      0.0  ...                            1.0   \n",
       "4                      0.0  ...                            0.0   \n",
       "\n",
       "   Education_Tertiary_Education  Default_Credit_no  Default_Credit_yes  \\\n",
       "0                           0.0                1.0                 0.0   \n",
       "1                           0.0                1.0                 0.0   \n",
       "2                           0.0                1.0                 0.0   \n",
       "3                           0.0                1.0                 0.0   \n",
       "4                           0.0                1.0                 0.0   \n",
       "\n",
       "   Housing_Loan_no  Housing_Loan_yes  Personal_Loan_no  Personal_Loan_yes  \\\n",
       "0              1.0               0.0               1.0                0.0   \n",
       "1              0.0               1.0               1.0                0.0   \n",
       "2              1.0               0.0               1.0                0.0   \n",
       "3              1.0               0.0               0.0                1.0   \n",
       "4              1.0               0.0               1.0                0.0   \n",
       "\n",
       "   Subscribed_no  Subscribed_yes  \n",
       "0            1.0             0.0  \n",
       "1            1.0             0.0  \n",
       "2            1.0             0.0  \n",
       "3            1.0             0.0  \n",
       "4            1.0             0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse = False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(tele_df[tele_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(tele_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our encoded categorical variables, we need to merge our encoded columns back into our original DataFrame (as well as remove the unencoded columns) and replace the unencoded categorical variables with the encoded variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Job_admin</th>\n",
       "      <th>Job_blue-collar</th>\n",
       "      <th>Job_entrepreneur</th>\n",
       "      <th>Job_management</th>\n",
       "      <th>Job_other</th>\n",
       "      <th>Job_retired</th>\n",
       "      <th>Job_self-employed</th>\n",
       "      <th>Job_services</th>\n",
       "      <th>Job_technician</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_Secondary_Education</th>\n",
       "      <th>Education_Tertiary_Education</th>\n",
       "      <th>Default_Credit_no</th>\n",
       "      <th>Default_Credit_yes</th>\n",
       "      <th>Housing_Loan_no</th>\n",
       "      <th>Housing_Loan_yes</th>\n",
       "      <th>Personal_Loan_no</th>\n",
       "      <th>Personal_Loan_yes</th>\n",
       "      <th>Subscribed_no</th>\n",
       "      <th>Subscribed_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Job_admin  Job_blue-collar  Job_entrepreneur  Job_management  \\\n",
       "0   56        0.0              0.0               0.0             0.0   \n",
       "1   37        0.0              0.0               0.0             0.0   \n",
       "2   40        1.0              0.0               0.0             0.0   \n",
       "3   56        0.0              0.0               0.0             0.0   \n",
       "4   59        1.0              0.0               0.0             0.0   \n",
       "\n",
       "   Job_other  Job_retired  Job_self-employed  Job_services  Job_technician  \\\n",
       "0        1.0          0.0                0.0           0.0             0.0   \n",
       "1        0.0          0.0                0.0           1.0             0.0   \n",
       "2        0.0          0.0                0.0           0.0             0.0   \n",
       "3        0.0          0.0                0.0           1.0             0.0   \n",
       "4        0.0          0.0                0.0           0.0             0.0   \n",
       "\n",
       "   ...  Education_Secondary_Education  Education_Tertiary_Education  \\\n",
       "0  ...                            0.0                           0.0   \n",
       "1  ...                            1.0                           0.0   \n",
       "2  ...                            0.0                           0.0   \n",
       "3  ...                            1.0                           0.0   \n",
       "4  ...                            0.0                           0.0   \n",
       "\n",
       "   Default_Credit_no  Default_Credit_yes  Housing_Loan_no  Housing_Loan_yes  \\\n",
       "0                1.0                 0.0              1.0               0.0   \n",
       "1                1.0                 0.0              0.0               1.0   \n",
       "2                1.0                 0.0              1.0               0.0   \n",
       "3                1.0                 0.0              1.0               0.0   \n",
       "4                1.0                 0.0              1.0               0.0   \n",
       "\n",
       "   Personal_Loan_no  Personal_Loan_yes  Subscribed_no  Subscribed_yes  \n",
       "0               1.0                0.0            1.0             0.0  \n",
       "1               1.0                0.0            1.0             0.0  \n",
       "2               1.0                0.0            1.0             0.0  \n",
       "3               0.0                1.0            1.0             0.0  \n",
       "4               1.0                0.0            1.0             0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "tele_df = tele_df.merge(encode_df, left_index = True, right_index = True)\n",
    "tele_df = tele_df.drop(tele_cat, 1)\n",
    "tele_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Job_admin', 'Job_blue-collar', 'Job_entrepreneur',\n",
       "       'Job_management', 'Job_other', 'Job_retired', 'Job_self-employed',\n",
       "       'Job_services', 'Job_technician', 'Marital_Status_divorced',\n",
       "       'Marital_Status_married', 'Marital_Status_single',\n",
       "       'Education_Primary_Education', 'Education_Professional_Education',\n",
       "       'Education_Secondary_Education', 'Education_Tertiary_Education',\n",
       "       'Default_Credit_no', 'Default_Credit_yes', 'Housing_Loan_no',\n",
       "       'Housing_Loan_yes', 'Personal_Loan_no', 'Personal_Loan_yes',\n",
       "       'Subscribed_no', 'Subscribed_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tele_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into the training and testing sets prior to standardization to not incorporate the testing values into the scale—testing values are only for evaluation. Perform the training/test split and standardize our numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove loan status target from features data\n",
    "y = tele_df.Subscribed_yes.values\n",
    "X = tele_df.drop(columns = [\"Subscribed_no\", \"Subscribed_yes\"]).values\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After standardizing variables in both the training and testing data, our dataset is ready for both models.\n",
    "\n",
    "Use the SVM’s linear kernel to try and create a linear boundary between the “Subscribed_yes” versus “Subscribed_no” groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVM model\n",
    "svm = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM model accuracy: 0.873\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "print(f\" SVM model accuracy: {accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output of our SVM model, the model was able to correctly predict the customers who subscribed roughly 87% of the time, which is a respectable first-pass model. \n",
    "\n",
    "Next, we need to compile and evaluate our deep learning model. Again, we’ll use our typical binary classifier parameters:\n",
    "* The first hidden layer will have an input_dim equal to the length of the scaled feature data X , 10 neuron units, and will use the relu activation function.\n",
    "* The second hidden layer will have 5 neuron units and also will use the relu activation function.\n",
    "* The loss function should be binary_crossentropy, using the adam optimizer.\n",
    "\n",
    "NOTE: Unlike our basic neural network model, we don’t want to use two to three times the number of neurons as input variables—we don’t want our deeper layers to overfit the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  10\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_nodes_layer1, \n",
    "                             input_dim = number_input_features, \n",
    "                             activation = \"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_nodes_layer2, \n",
    "                             activation = \"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units = 1, \n",
    "                             activation = \"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss = \"binary_crossentropy\", \n",
    "           optimizer = \"adam\", \n",
    "           metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22857 samples\n",
      "Epoch 1/50\n",
      "22857/22857 [==============================] - 4s 175us/sample - loss: 0.4114 - accuracy: 0.8575\n",
      "Epoch 2/50\n",
      "22857/22857 [==============================] - 2s 93us/sample - loss: 0.3732 - accuracy: 0.8735\n",
      "Epoch 3/50\n",
      "22857/22857 [==============================] - 2s 89us/sample - loss: 0.3700 - accuracy: 0.8735\n",
      "Epoch 4/50\n",
      "22857/22857 [==============================] - 2s 89us/sample - loss: 0.3688 - accuracy: 0.8735\n",
      "Epoch 5/50\n",
      "22857/22857 [==============================] - 2s 91us/sample - loss: 0.3676 - accuracy: 0.8735\n",
      "Epoch 6/50\n",
      "22857/22857 [==============================] - 2s 98us/sample - loss: 0.3670 - accuracy: 0.8735\n",
      "Epoch 7/50\n",
      "22857/22857 [==============================] - 2s 91us/sample - loss: 0.3665 - accuracy: 0.8735\n",
      "Epoch 8/50\n",
      "22857/22857 [==============================] - 2s 91us/sample - loss: 0.3659 - accuracy: 0.8735\n",
      "Epoch 9/50\n",
      "22857/22857 [==============================] - 2s 95us/sample - loss: 0.3654 - accuracy: 0.8735\n",
      "Epoch 10/50\n",
      "22857/22857 [==============================] - 2s 99us/sample - loss: 0.3650 - accuracy: 0.8735\n",
      "Epoch 11/50\n",
      "22857/22857 [==============================] - 3s 110us/sample - loss: 0.3647 - accuracy: 0.8735\n",
      "Epoch 12/50\n",
      "22857/22857 [==============================] - 2s 108us/sample - loss: 0.3646 - accuracy: 0.8735\n",
      "Epoch 13/50\n",
      "22857/22857 [==============================] - 3s 110us/sample - loss: 0.3642 - accuracy: 0.8735\n",
      "Epoch 14/50\n",
      "22857/22857 [==============================] - 2s 90us/sample - loss: 0.3641 - accuracy: 0.8735\n",
      "Epoch 15/50\n",
      "22857/22857 [==============================] - 2s 91us/sample - loss: 0.3640 - accuracy: 0.8735\n",
      "Epoch 16/50\n",
      "22857/22857 [==============================] - 2s 89us/sample - loss: 0.3638 - accuracy: 0.8735\n",
      "Epoch 17/50\n",
      "22857/22857 [==============================] - 2s 103us/sample - loss: 0.3637 - accuracy: 0.8735\n",
      "Epoch 18/50\n",
      "22857/22857 [==============================] - 2s 83us/sample - loss: 0.3635 - accuracy: 0.8735\n",
      "Epoch 19/50\n",
      "22857/22857 [==============================] - 3s 127us/sample - loss: 0.3634 - accuracy: 0.8735\n",
      "Epoch 20/50\n",
      "22857/22857 [==============================] - 3s 142us/sample - loss: 0.3632 - accuracy: 0.8735\n",
      "Epoch 21/50\n",
      "22857/22857 [==============================] - 3s 118us/sample - loss: 0.3632 - accuracy: 0.8735\n",
      "Epoch 22/50\n",
      "22857/22857 [==============================] - 2s 105us/sample - loss: 0.3631 - accuracy: 0.8735\n",
      "Epoch 23/50\n",
      "22857/22857 [==============================] - 3s 117us/sample - loss: 0.3630 - accuracy: 0.8735\n",
      "Epoch 24/50\n",
      "22857/22857 [==============================] - 2s 109us/sample - loss: 0.3630 - accuracy: 0.8735\n",
      "Epoch 25/50\n",
      "22857/22857 [==============================] - 2s 107us/sample - loss: 0.3628 - accuracy: 0.8735 - loss: 0.3626 - accuracy:  - ETA: 0s - loss: 0.3635 - accuracy\n",
      "Epoch 26/50\n",
      "22857/22857 [==============================] - 3s 115us/sample - loss: 0.3629 - accuracy: 0.8735\n",
      "Epoch 27/50\n",
      "22857/22857 [==============================] - 2s 105us/sample - loss: 0.3627 - accuracy: 0.8735 - loss: 0.3\n",
      "Epoch 28/50\n",
      "22857/22857 [==============================] - 2s 96us/sample - loss: 0.3627 - accuracy: 0.8735s - l - ETA: 0s - loss: 0.3635 - \n",
      "Epoch 29/50\n",
      "22857/22857 [==============================] - 2s 95us/sample - loss: 0.3625 - accuracy: 0.8735\n",
      "Epoch 30/50\n",
      "22857/22857 [==============================] - 2s 98us/sample - loss: 0.3623 - accuracy: 0.8735\n",
      "Epoch 31/50\n",
      "22857/22857 [==============================] - 2s 100us/sample - loss: 0.3624 - accuracy: 0.8735\n",
      "Epoch 32/50\n",
      "22857/22857 [==============================] - 2s 102us/sample - loss: 0.3623 - accuracy: 0.8735\n",
      "Epoch 33/50\n",
      "22857/22857 [==============================] - 2s 100us/sample - loss: 0.3623 - accuracy: 0.8735\n",
      "Epoch 34/50\n",
      "22857/22857 [==============================] - 2s 107us/sample - loss: 0.3621 - accuracy: 0.8735\n",
      "Epoch 35/50\n",
      "22857/22857 [==============================] - 3s 113us/sample - loss: 0.3622 - accuracy: 0.8735\n",
      "Epoch 36/50\n",
      "22857/22857 [==============================] - 2s 109us/sample - loss: 0.3623 - accuracy: 0.8735\n",
      "Epoch 37/50\n",
      "22857/22857 [==============================] - 5s 225us/sample - loss: 0.3621 - accuracy: 0.8735\n",
      "Epoch 38/50\n",
      "22857/22857 [==============================] - 5s 223us/sample - loss: 0.3619 - accuracy: 0.8735\n",
      "Epoch 39/50\n",
      "22857/22857 [==============================] - 6s 243us/sample - loss: 0.3621 - accuracy: 0.8735\n",
      "Epoch 40/50\n",
      "22857/22857 [==============================] - 4s 162us/sample - loss: 0.3619 - accuracy: 0.8735\n",
      "Epoch 41/50\n",
      "22857/22857 [==============================] - 4s 193us/sample - loss: 0.3617 - accuracy: 0.8735\n",
      "Epoch 42/50\n",
      "22857/22857 [==============================] - 4s 178us/sample - loss: 0.3618 - accuracy: 0.8735\n",
      "Epoch 43/50\n",
      "22857/22857 [==============================] - 3s 147us/sample - loss: 0.3618 - accuracy: 0.8735\n",
      "Epoch 44/50\n",
      "22857/22857 [==============================] - 3s 111us/sample - loss: 0.3615 - accuracy: 0.8735\n",
      "Epoch 45/50\n",
      "22857/22857 [==============================] - 3s 112us/sample - loss: 0.3616 - accuracy: 0.8735\n",
      "Epoch 46/50\n",
      "22857/22857 [==============================] - 3s 131us/sample - loss: 0.3616 - accuracy: 0.8735\n",
      "Epoch 47/50\n",
      "22857/22857 [==============================] - 3s 150us/sample - loss: 0.3616 - accuracy: 0.8735\n",
      "Epoch 48/50\n",
      "22857/22857 [==============================] - 3s 123us/sample - loss: 0.3614 - accuracy: 0.8735 - loss: 0.3628 - accu\n",
      "Epoch 49/50\n",
      "22857/22857 [==============================] - 3s 148us/sample - loss: 0.3615 - accuracy: 0.8735\n",
      "Epoch 50/50\n",
      "22857/22857 [==============================] - 3s 143us/sample - loss: 0.3613 - accuracy: 0.8735\n",
      "7620/1 - 1s - loss: 0.5287 - accuracy: 0.8735\n",
      "Loss: 0.37204879597416074, Accuracy: 0.8734908103942871\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs = 50) \n",
    "\n",
    "# Evaluate the model using the test data \n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results of our comparative analysis, the SVM and deep learning models both achieved a predictive accuracy around 87%. \n",
    "* Additionally, both models take similar amounts of time to train on the input data. \n",
    "* The only noticeable difference between the two models is implementation.\n",
    "    * The amount of code required to build and train the SVM is notably less than the comparable deep learning model. \n",
    "* As a result, many data scientists will prefer to use SVMs by default, then turn to deep learning models, as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
